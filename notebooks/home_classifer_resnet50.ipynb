{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement a ResNet-based classifier for house-style classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '../visual_home_finder')\n",
    "import config, paths\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Input, Dense, AveragePooling2D, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from tensorflow import math\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of training, validation and test images\n",
    "num_train = len(list(paths.list_images(config.TRAIN_PATH)))\n",
    "num_val = len(list(paths.list_images(config.VAL_PATH)))\n",
    "num_test = len(list(paths.list_images(config.TEST_PATH)))\n",
    "print(num_train, num_val, num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function for finding the mean and std of the training images\n",
    "# images = list(paths.list_images(config.TRAIN_PATH))\n",
    "# img_mean = 0\n",
    "# img_var = 0\n",
    "# for ii in range(num_train):    \n",
    "#     img = image.load_img(images[ii], target_size = (224,224))\n",
    "#     img = image.img_to_array(img)\n",
    "#     img_mean += img.mean((0,1))\n",
    "#     img_var += img.var((0,1))\n",
    "# img_mean = img_mean/num_train\n",
    "# img_std = np.sqrt(img_var/num_train)\n",
    "img_mean = config.IMG_MEAN #np.array([123.526794, 129.04448, 119.95359], dtype=np.float32).reshape((1,1,3))\n",
    "#img_std = 62#np.array([62.082836, 61.87381, 73.08175], dtype=np.float32).reshape((1,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(img_mean, img_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training data augmentation object\n",
    "train_aug = ImageDataGenerator(\n",
    "    featurewise_center = True,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "train_aug.mean = img_mean\n",
    "\n",
    "# Initialize validation data augmentation object\n",
    "val_aug = ImageDataGenerator(featurewise_center = True)\n",
    "val_aug.mean = img_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Just to test that the normalization is working correctly\n",
    "# iterator = train_aug.flow_from_directory(\n",
    "#     config.TRAIN_PATH,\n",
    "#     class_mode=\"categorical\",\n",
    "#     target_size=(224, 224),\n",
    "#     color_mode=\"rgb\",\n",
    "#     shuffle=True,\n",
    "#     batch_size=batch_size)\n",
    "# batchX, batchy = iterator.next()\n",
    "# print(batchX.shape, batchX.mean(), batchX.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functions for generating training, test and validation data\n",
    "batch_size = 32\n",
    "\n",
    "train_gen = train_aug.flow_from_directory(\n",
    "    config.TRAIN_PATH,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_gen = val_aug.flow_from_directory(\n",
    "    config.VAL_PATH,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_gen = val_aug.flow_from_directory(\n",
    "    config.TEST_PATH,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ResNet model with the last classification layer removed\n",
    "base_model = ResNet50(weights='imagenet', include_top = False, \n",
    "                      input_tensor = Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new layers to the base model\n",
    "new_model = base_model.output\n",
    "new_model = AveragePooling2D(pool_size=(7,7))(new_model)\n",
    "new_model = Flatten(name='flatten')(new_model)\n",
    "new_model = Dense(256, activation='relu')(new_model)\n",
    "new_model = Dropout(0.5)(new_model)\n",
    "new_model = Dense(len(config.CLASSES), activation=\"softmax\")(new_model)\n",
    "\n",
    "# Place new model at head of the base model\n",
    "model = Model(inputs=base_model.input, outputs=new_model)\n",
    "\n",
    "# Freeze all layers of base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "initial_lr = 0.001\n",
    "num_epochs = 5\n",
    "\n",
    "opt = Adam(lr = initial_lr, decay=initial_lr /5)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "              metrics=[\"accuracy\", 'AUC'])\n",
    "\n",
    "model_history = model.fit(\n",
    "            train_gen,\n",
    "            steps_per_epoch=num_train // batch_size,\n",
    "            validation_data=val_gen,\n",
    "            #validation_steps=num_val // batch_size,\n",
    "            epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reset test generator and used trained model to make predictions\n",
    "print(\"Evaluating network...\")\n",
    "test_gen.reset()\n",
    "pred_indices_raw = model.predict(test_gen)\n",
    "# For each image, find the class\n",
    "pred_indices = np.argmax(pred_indices_raw, axis=1)\n",
    "# Classification Report\n",
    "print(classification_report(test_gen.classes, pred_indices, \n",
    "                 target_names=test_gen.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize model to disk\n",
    "print(\"Save Model...\")\n",
    "model.save(os.path.sep.join([config.MODEL_PATH, 'home_model'], save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reset the testing generator and then use our trained model to\n",
    "# # make predictions on the data\n",
    "# print(\"[INFO] evaluating network...\")\n",
    "# test_train_gen.reset()\n",
    "# pred_indices_raw = model.predict(test_train_gen)\n",
    "# # for each image in the testing set we need to find the index of the\n",
    "# # label with corresponding largest predicted probability\n",
    "# pred_indices = np.argmax(pred_indices_raw, axis=1)\n",
    "# # show a nicely formatted classification report\n",
    "# print(classification_report(test_train_gen.classes, pred_indices, \n",
    "#                  target_names=test_train_gen.class_indices.keys()))\n",
    "# # serialize the model to disk\n",
    "# print(\"[INFO] savconfig.MODEL_PATHODEL_PATHl...\")\n",
    "# model.save(config.MODEL_PATH, save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "con_mat = math.confusion_matrix(test_gen.classes, predictions=pred_indices).numpy()\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                     index = config.CLASSES, \n",
    "                     columns = config.CLASSES)\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = num_epochs\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), model_history.history[\"loss\"], '*-', label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), model_history.history[\"val_loss\"], '*-', label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), model_history.history[\"accuracy\"], '*-', label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), model_history.history[\"val_accuracy\"], '*-', label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_test_images = list(paths.list_images(config.TEST_PATH))\n",
    "index = 101\n",
    "print(some_test_images[index])\n",
    "\n",
    "img = image.load_img(some_test_images[index], target_size = (224,224))\n",
    "orig_img = image.img_to_array(img)\n",
    "img = np.expand_dims(orig_img - img_mean, axis = 0)\n",
    "\n",
    "model_output = model.predict(img)\n",
    "print(model_output)\n",
    "print(config.CLASSES[np.argmax(np.ravel(model_output))])\n",
    "plt.imshow(orig_img/255)\n",
    "print(config.CLASSES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
