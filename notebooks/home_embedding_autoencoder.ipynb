{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build an Autoencoder for creating home-embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '../visual_home_finder')\n",
    "import config, paths\n",
    "\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various input parameters for the model\n",
    "training_file = \"training_data.pickle\"\n",
    "validation_file = \"validation_data.pickle\"\n",
    "test_file = \"test_data.pickle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a datastructure that contains training, validation and test data. This only needs to be done once. If pickle file with data is already available, just load that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_files_into_numpy_array(list_of_files, image_size):\n",
    "    data = list()\n",
    "    for ff in list_of_files:\n",
    "        image_pil = image.load_img(ff, target_size = (image_size,image_size))\n",
    "        image_array = image.img_to_array(image_pil)\n",
    "        image_array = image_array/256 # Normalize array to be between zero and 1\n",
    "        data.append(image_array)\n",
    "    data = np.array(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Training, Validation and Test data in to numpy arrays\n",
    "num_test = len(list(paths.list_images(config.TEST_PATH)))\n",
    "\n",
    "if not os.path.isfile(training_file):\n",
    "    train_files = list(paths.list_images(config.TRAIN_PATH))\n",
    "    print('Number of training images are : %d'%len(train_files))\n",
    "    training_data = load_images_from_files_into_numpy_array(train_files, IMG_SIZE)\n",
    "    pickle.dump(training_data, open(training_file, 'wb'))\n",
    "else:\n",
    "    training_data = pickle.load(open(training_file, 'rb'))\n",
    "print('Shape of Training data is '+ str(np.shape(training_data)))\n",
    "        \n",
    "if not os.path.isfile(validation_file):\n",
    "    val_files = list(paths.list_images(config.VAL_PATH))\n",
    "    print('Number of validation images are : %d'%len(val_files))\n",
    "    validation_data = load_images_from_files_into_numpy_array(val_files, IMG_SIZE)\n",
    "    pickle.dump(validation_data, open(validation_file, 'wb'))\n",
    "else:\n",
    "    validation_data = pickle.load(open(validation_file, 'rb'))\n",
    "print('Shape of Validation data is '+ str(np.shape(validation_data)))\n",
    "\n",
    "if not os.path.isfile(test_file):\n",
    "    test_files = list(paths.list_images(config.TEST_PATH))\n",
    "    print('Number of test images are : %d'%len(test_files))\n",
    "    test_data = load_images_from_files_into_numpy_array(test_files, IMG_SIZE)\n",
    "    pickle.dump(test_data, open(test_file, 'wb'))\n",
    "else:\n",
    "    test_data = pickle.load(open(test_file, 'rb'))\n",
    "print('Shape of Test data is '+ str(np.shape(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_aug = ImageDataGenerator(\n",
    "#     zoom_range=0.1,\n",
    "#     width_shift_range=0.1,\n",
    "#     height_shift_range=0.1,\n",
    "#     shear_range=0.1,\n",
    "#     horizontal_flip=True,\n",
    "#     fill_mode=\"nearest\")  # To scale each image between -1 and 1\n",
    "\n",
    "# # Initialize validation data augmentation object\n",
    "# val_aug = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Just for testing the normalizations on the data\n",
    "# batch_size = 32\n",
    "# iterator = train_aug.flow(\n",
    "#     x = training_data,\n",
    "#     shuffle = True,\n",
    "#     batch_size=batch_size)\n",
    "# batchX = iterator.next()\n",
    "# # Mean should be around 0, Max and min should be within [-1,1]\n",
    "# print(batchX.shape, batchX.mean(), batchX.max(), batchX.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the training, test and validation flow\n",
    "# batch_size = 32\n",
    "# train_gen = train_aug.flow(\n",
    "#     x = training_data,\n",
    "#     shuffle = True,\n",
    "#     batch_size=batch_size)\n",
    "\n",
    "# val_gen = train_aug.flow(\n",
    "#     x = training_data,\n",
    "#     shuffle = False,\n",
    "#     batch_size=batch_size)\n",
    "\n",
    "# test_gen = train_aug.flow(\n",
    "#     x = test_data,\n",
    "#     shuffle = False,\n",
    "#     batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Auto-encoder model\n",
    "\n",
    "input_img = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "model = Conv2D(8, (3, 3), activation='relu', padding='same')(input_img)  # O/P shape = (224, 224, 8)\n",
    "model = MaxPooling2D((2, 2))(model)  # O/P shape = (112, 112, 8)\n",
    "model = Conv2D(16, (3, 3), activation='relu', padding='same')(model)  # O/P shape = (112, 112, 16)\n",
    "model = MaxPooling2D((2, 2))(model)  # O/P shape = (56, 56, 16)\n",
    "model = Conv2D(32, (3, 3), activation='relu', padding='same')(model)  # O/P shape = (56, 56, 32)\n",
    "model = MaxPooling2D((2, 2))(model)  # O/P shape = (28, 28, 32)\n",
    "model = Conv2D(64, (3, 3), activation='relu', padding='same')(model)  # O/P shape = (28, 28, 64)\n",
    "model = MaxPooling2D((2, 2))(model)  # O/P shape = (14, 14, 64)\n",
    "model = Conv2D(128, (3, 3), activation='relu', padding='same')(model)  # O/P shape = (28, 28, 128)\n",
    "encoded = MaxPooling2D((2, 2))(model)  # O/P shape = (7, 7, 128)\n",
    "\n",
    "model = Conv2D(128, (3, 3), activation='relu', padding='same')(encoded)  # O/P shape = (7, 7, 128)\n",
    "model = UpSampling2D((2, 2)) (model)  # O/P shape = (14, 14, 128)\n",
    "model = Conv2D(64, (3, 3), activation='relu', padding='same')(model)  # O/P shape = (14, 14, 64)\n",
    "model = UpSampling2D((2, 2)) (model)  # O/P shape = (28, 28, 64)\n",
    "model = Conv2D(32, (3, 3), activation='relu', padding='same')(model)  # O/P shape = (28, 28, 32)\n",
    "model = UpSampling2D((2, 2)) (model)  # O/P shape = (56, 56, 32)\n",
    "model = Conv2D(16, (3, 3), activation='relu', padding='same')(model)  # O/P shape = (56, 56, 16)\n",
    "model = UpSampling2D((2, 2)) (model)  # O/P shape = (112, 112, 16)\n",
    "model = Conv2D(8, (3, 3), activation='relu', padding='same')(model)  # O/P shape = (112, 112, 8)\n",
    "model = UpSampling2D((2, 2)) (model)  # O/P shape = (224, 224, 8)\n",
    "decoded = Conv2D(3, (3, 3), activation='relu', padding='same')(model)  # O/P shape = (224, 224, 3)\n",
    "\n",
    "my_first_autoencoder = Model(input_img, decoded)\n",
    "\n",
    "initial_lr = 0.001\n",
    "opt = Adam(lr = initial_lr)\n",
    "\n",
    "my_first_autoencoder.compile(loss=\"mse\", optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_first_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "batch_size = 32\n",
    "model_history = my_first_autoencoder.fit(\n",
    "            training_data, training_data,\n",
    "            batch_size = batch_size,\n",
    "            shuffle = True,\n",
    "            validation_data= (validation_data, validation_data),\n",
    "            epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = num_epochs\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), model_history.history[\"loss\"], '*-', label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), model_history.history[\"val_loss\"], '*-', label=\"val_loss\")\n",
    "plt.title(\"Training Loss on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_first_autoencoder.save(\"my_first_encoder.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
